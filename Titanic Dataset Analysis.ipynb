{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "trainDataFileName = \"train.csv\"\n",
    "descriptionFileName = \"Description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Description\nOverview\n\nThe data has been split into two groups:\n\ntraining set (train.csv)\ntest set (test.csv)\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n\nData Dictionary\n\nVariable\tDefinition\tKey\nsurvival\tSurvival\t0 = No, 1 = Yes\npclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex\tSex\t\nAge\tAge in years\t\nsibsp\t# of siblings / spouses aboard the Titanic\t\nparch\t# of parents / children aboard the Titanic\t\nticket\tTicket number\t\nfare\tPassenger fare\t\ncabin\tCabin number\t\nembarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\nVariable Notes\n\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fiancés were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.\n\n"
     ]
    }
   ],
   "source": [
    "with open(descriptionFileName) as f:\n",
    "    read_data=f.read()\n",
    "    print(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.dropna(pd.read_csv(trainDataFileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      PassengerId  Survived  Pclass  \\\n1              2         1       1   \n3              4         1       1   \n6              7         0       1   \n10            11         1       3   \n11            12         1       1   \n21            22         1       2   \n23            24         1       1   \n27            28         0       1   \n52            53         1       1   \n54            55         0       1   \n62            63         0       1   \n66            67         1       2   \n75            76         0       3   \n88            89         1       1   \n92            93         0       1   \n96            97         0       1   \n97            98         1       1   \n102          103         0       1   \n110          111         0       1   \n118          119         0       1   \n123          124         1       2   \n124          125         0       1   \n136          137         1       1   \n137          138         0       1   \n139          140         0       1   \n148          149         0       2   \n151          152         1       1   \n170          171         0       1   \n174          175         0       1   \n177          178         0       1   \n..           ...       ...     ...   \n737          738         1       1   \n741          742         0       1   \n742          743         1       1   \n745          746         0       1   \n748          749         0       1   \n751          752         1       3   \n759          760         1       1   \n763          764         1       1   \n765          766         1       1   \n772          773         0       2   \n779          780         1       1   \n781          782         1       1   \n782          783         0       1   \n789          790         0       1   \n796          797         1       1   \n802          803         1       1   \n806          807         0       1   \n809          810         1       1   \n820          821         1       1   \n823          824         1       3   \n835          836         1       1   \n853          854         1       1   \n857          858         1       1   \n862          863         1       1   \n867          868         0       1   \n871          872         1       1   \n872          873         0       1   \n879          880         1       1   \n887          888         1       1   \n889          890         1       1   \n\n                                                  Name     Sex   Age  SibSp  \\\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n6                              McCarthy, Mr. Timothy J    male  54.0      0   \n10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n21                               Beesley, Mr. Lawrence    male  34.0      0   \n23                        Sloper, Mr. William Thompson    male  28.0      0   \n27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n52            Harper, Mrs. Henry Sleeper (Myna Haxtun)  female  49.0      1   \n54                      Ostby, Mr. Engelhart Cornelius    male  65.0      0   \n62                         Harris, Mr. Henry Birkhardt    male  45.0      1   \n66                        Nye, Mrs. (Elizabeth Ramell)  female  29.0      0   \n75                             Moen, Mr. Sigurd Hansen    male  25.0      0   \n88                          Fortune, Miss. Mabel Helen  female  23.0      3   \n92                         Chaffee, Mr. Herbert Fuller    male  46.0      1   \n96                           Goldschmidt, Mr. George B    male  71.0      0   \n97                     Greenfield, Mr. William Bertram    male  23.0      0   \n102                          White, Mr. Richard Frasar    male  21.0      0   \n110                     Porter, Mr. Walter Chamberlain    male  47.0      0   \n118                           Baxter, Mr. Quigg Edmond    male  24.0      0   \n123                                Webber, Miss. Susan  female  32.5      0   \n124                        White, Mr. Percival Wayland    male  54.0      0   \n136                       Newsom, Miss. Helen Monypeny  female  19.0      0   \n137                        Futrelle, Mr. Jacques Heath    male  37.0      1   \n139                                 Giglio, Mr. Victor    male  24.0      0   \n148           Navratil, Mr. Michel (\"Louis M Hoffman\")    male  36.5      0   \n151                  Pears, Mrs. Thomas (Edith Wearne)  female  22.0      1   \n170                          Van der hoef, Mr. Wyckoff    male  61.0      0   \n174                            Smith, Mr. James Clinch    male  56.0      0   \n177                         Isham, Miss. Ann Elizabeth  female  50.0      0   \n..                                                 ...     ...   ...    ...   \n737                             Lesurer, Mr. Gustave J    male  35.0      0   \n741                      Cavendish, Mr. Tyrell William    male  36.0      1   \n742              Ryerson, Miss. Susan Parker \"Suzette\"  female  21.0      2   \n745                       Crosby, Capt. Edward Gifford    male  70.0      1   \n748                          Marvin, Mr. Daniel Warner    male  19.0      1   \n751                                Moor, Master. Meier    male   6.0      0   \n759  Rothes, the Countess. of (Lucy Noel Martha Dye...  female  33.0      0   \n763          Carter, Mrs. William Ernest (Lucile Polk)  female  36.0      1   \n765               Hogeboom, Mrs. John C (Anna Andrews)  female  51.0      1   \n772                                  Mack, Mrs. (Mary)  female  57.0      0   \n779  Robert, Mrs. Edward Scott (Elisabeth Walton Mc...  female  43.0      0   \n781          Dick, Mrs. Albert Adrian (Vera Gillespie)  female  17.0      1   \n782                             Long, Mr. Milton Clyde    male  29.0      0   \n789                           Guggenheim, Mr. Benjamin    male  46.0      0   \n796                        Leader, Dr. Alice (Farnham)  female  49.0      0   \n802                Carter, Master. William Thornton II    male  11.0      1   \n806                             Andrews, Mr. Thomas Jr    male  39.0      0   \n809     Chambers, Mrs. Norman Campbell (Bertha Griggs)  female  33.0      1   \n820  Hays, Mrs. Charles Melville (Clara Jennings Gr...  female  52.0      1   \n823                                 Moor, Mrs. (Beila)  female  27.0      0   \n835                        Compton, Miss. Sara Rebecca  female  39.0      1   \n853                          Lines, Miss. Mary Conover  female  16.0      0   \n857                             Daly, Mr. Peter Denis     male  51.0      0   \n862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n\n     Parch       Ticket      Fare            Cabin Embarked  \n1        0     PC 17599   71.2833              C85        C  \n3        0       113803   53.1000             C123        S  \n6        0        17463   51.8625              E46        S  \n10       1      PP 9549   16.7000               G6        S  \n11       0       113783   26.5500             C103        S  \n21       0       248698   13.0000              D56        S  \n23       0       113788   35.5000               A6        S  \n27       2        19950  263.0000      C23 C25 C27        S  \n52       0     PC 17572   76.7292              D33        C  \n54       1       113509   61.9792              B30        C  \n62       0        36973   83.4750              C83        S  \n66       0   C.A. 29395   10.5000              F33        S  \n75       0       348123    7.6500            F G73        S  \n88       2        19950  263.0000      C23 C25 C27        S  \n92       0  W.E.P. 5734   61.1750              E31        S  \n96       0     PC 17754   34.6542               A5        C  \n97       1     PC 17759   63.3583          D10 D12        C  \n102      1        35281   77.2875              D26        S  \n110      0       110465   52.0000             C110        S  \n118      1     PC 17558  247.5208          B58 B60        C  \n123      0        27267   13.0000             E101        S  \n124      1        35281   77.2875              D26        S  \n136      2        11752   26.2833              D47        S  \n137      0       113803   53.1000             C123        S  \n139      0     PC 17593   79.2000              B86        C  \n148      2       230080   26.0000               F2        S  \n151      0       113776   66.6000               C2        S  \n170      0       111240   33.5000              B19        S  \n174      0        17764   30.6958               A7        C  \n177      0     PC 17595   28.7125              C49        C  \n..     ...          ...       ...              ...      ...  \n737      0     PC 17755  512.3292             B101        C  \n741      0        19877   78.8500              C46        S  \n742      2     PC 17608  262.3750  B57 B59 B63 B66        C  \n745      1    WE/P 5735   71.0000              B22        S  \n748      0       113773   53.1000              D30        S  \n751      1       392096   12.4750             E121        S  \n759      0       110152   86.5000              B77        S  \n763      2       113760  120.0000          B96 B98        S  \n765      0        13502   77.9583              D11        S  \n772      0  S.O./P.P. 3   10.5000              E77        S  \n779      1        24160  211.3375               B3        S  \n781      0        17474   57.0000              B20        S  \n782      0       113501   30.0000               D6        S  \n789      0     PC 17593   79.2000          B82 B84        C  \n796      0        17465   25.9292              D17        S  \n802      2       113760  120.0000          B96 B98        S  \n806      0       112050    0.0000              A36        S  \n809      0       113806   53.1000               E8        S  \n820      1        12749   93.5000              B69        S  \n823      1       392096   12.4750             E121        S  \n835      1     PC 17756   83.1583              E49        C  \n853      1     PC 17592   39.4000              D28        S  \n857      0       113055   26.5500              E17        S  \n862      0        17466   25.9292              D17        S  \n867      0     PC 17590   50.4958              A24        S  \n871      1        11751   52.5542              D35        S  \n872      0          695    5.0000      B51 B53 B55        S  \n879      1        11767   83.1583              C50        C  \n887      0       112053   30.0000              B42        S  \n889      0       111369   30.0000             C148        C  \n\n[183 rows x 12 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalVariables = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "numericalVariables = [\"SibSp\", \"Parch\", \"Fare\", \"Age\"]\n",
    "otherVariables = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.25408475],\n       [-0.25408475,  1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(x=data['Survived'],y=data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do:\n",
    "\n",
    "1. Apply standard skl routines to dataset and evaluate performance for multiple train-test splits.\n",
    "2. Do a Feature Analysis: Correlations (incl significance analysis for p=0.05), Na-Values, Some Splits for nonlinear behavior (categorical variables with <5 values)\n",
    "3. Feature Engineering: Something found in Name, Ticket Number, Cabin number? Merge sibs/parch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Start with naive application of standard skl routines\n",
    "\n",
    "To give a first overview we want to apply standard prediction routines to get an idea of what is possible without spending time in Feature Analysis, Feature Engineering and fine-tuning of algorithmic parameters.\n",
    "\n",
    "We delete \"non-essential\" columns (columns that can not directly be used for any prediction model without Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of people survived in test set: 69.1%\n##### Logistic Regression:\nTotal test: 123\nSurvived test: 85\nCorrect Predictions: 94\n###### Random Forest Classifier:\nTotal test: 123\nSurvived test: 85\nCorrect Predictions: 94\n"
     ]
    }
   ],
   "source": [
    "filteredData = data.drop(otherVariables, axis=1) # Remove non-essential columns\n",
    "filteredData = pd.get_dummies(filteredData, columns=categoricalVariables) # Create dummy Variables for categorical data\n",
    "# Split Training and Test set:\n",
    "train=filteredData.sample(frac=0.33,random_state=42)\n",
    "test=filteredData.drop(train.index)\n",
    "print('Percentage of people survived in test set: {:2.1f}%'.format(100*sum(test[\"Survived\"])/len(test[\"Survived\"])))\n",
    "\n",
    "# Apply logistic regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "logReg = linear_model.LogisticRegression()\n",
    "logReg.fit(X=train.drop(\"Survived\",axis=1), y=train[\"Survived\"])\n",
    "resultslogReg=pd.DataFrame(logReg.predict(test.drop(\"Survived\", axis=1)), columns=[\"prediction\"])\n",
    "resultslogReg=pd.concat([test.reset_index(),resultslogReg],axis=1)\n",
    "diff= resultslogReg[\"prediction\"]- resultslogReg[\"Survived\"]\n",
    "print('##### Logistic Regression:\\nTotal test: {}\\nSurvived test: {}\\nCorrect Predictions: {}'.format(len(resultslogReg[\"Survived\"]), sum(resultslogReg[\"Survived\"]), (len(resultslogReg[\"Survived\"])- sum(abs(diff)))))\n",
    "\n",
    "\n",
    "# Apply Random Forest Classifier\n",
    "\n",
    "from sklearn import ensemble\n",
    "\n",
    "prf = ensemble.RandomForestClassifier(random_state=42)\n",
    "prf.fit(X=train.drop(\"Survived\",axis=1), y=train[\"Survived\"])\n",
    "resultsprf=pd.DataFrame(prf.predict(test.drop(\"Survived\", axis=1)), columns=[\"prediction\"])\n",
    "resultsprf=pd.concat([test.reset_index(),resultsprf],axis=1)\n",
    "diff= resultsprf[\"prediction\"]- resultsprf[\"Survived\"]\n",
    "print('###### Random Forest Classifier:\\nTotal test: {}\\nSurvived test: {}\\nCorrect Predictions: {}'.format(len(resultsprf[\"Survived\"]), sum(resultsprf[\"Survived\"]), (len(resultsprf[\"Survived\"])- sum(abs(diff)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the performance of the Random Forest Classifier varies with its random state."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
